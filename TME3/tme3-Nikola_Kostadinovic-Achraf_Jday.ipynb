{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage de paramètres par maximum de vraisemblance\n",
    "Dans ce TME, l'objectif est d'apprendre grâce à l'estimateur de maximum de vraisemblance les paramètres de lois normales à partir d'un ensemble de données. Ces lois normales seront ensuite exploitées pour faire de la classification (comme nous l'avions vu en cours avec les images de désert, forêt, mer et paysages enneigés).\n",
    "\n",
    "Ici, notre base de données d'apprentissage est la base USPS. Celle-ci contient les images réelles de chiffres provenant de codes postaux écrits manuellement et scannés par le service des postes américain. Ces données scannées ont été normalisées de manière à ce qu'elles soient toutes des images de 16x16 pixels en teintes de gris, cf. Le Cun et al., 1990:\n",
    "\n",
    "Y. LeCun, O. Matan, B. Boser, J. S. Denker, et al. (1990) *Handwritten zip code recognition with multilayer networks*. In ICPR, volume II, pages 35–40.\n",
    "\n",
    "Voici quelques exemples d'images de cette base : \n",
    "\n",
    "<img src=\"usps.png\" title=\"Quelques exemples\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données et premières visualisations\n",
    "\n",
    "Nous utiliserons la librairie pickle qui permet de sérialiser les objets en python (ie, les sauver et les charger très facilement).\n",
    "Une fois les données chargées, nous allons étudier très rapidement la distribution des classes, visualiser une imagette de chiffre et comprendre l'encodage de ces chiffres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([488., 412., 311., 260., 306., 244., 261., 282., 224., 281.]),\n",
       " array([-0.5,  0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chargement des données\n",
    "data = pkl.load(open(\"usps.pkl\",'rb')) \n",
    "# data est un dictionnaire contenant les champs explicites X_train, X_test, Y_train, Y_test\n",
    "X_train = np.array(data[\"X_train\"],dtype=float) # changement de type pour éviter les problèmes d'affichage\n",
    "X_test = np.array(data[\"X_test\"],dtype=float)\n",
    "Y_train = data[\"Y_train\"]\n",
    "Y_test = data[\"Y_test\"]\n",
    "\n",
    "# visualisation de la distribution des étiquettes (dans les 10 classes de chiffres)\n",
    "plt.figure()\n",
    "plt.hist(Y_train, np.linspace(-0.5,9.5,11))\n",
    "plt.hist(Y_test, np.linspace(-0.5,9.5,11))\n",
    "#plt.savefig(\"distr_classes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6229, 256)\n",
      "(3069, 256) (6229,) (3069,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image de : 6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prise en main des matrices X, Y\n",
    "print(X_train.shape)\n",
    "# 6229 images composées de 256 pixels (image = 16x16)\n",
    "print(X_test.shape,Y_train.shape, Y_test.shape)\n",
    "\n",
    "# Affichage de l'image 18 de la base de données et récupération de l'étiquette associée:\n",
    "# (1) remise en forme de la ligne de 256 pixels en 16x16\n",
    "# (2) affichage avec imshow (en niveaux de gris)\n",
    "# (3) récupération de l'étiquette dans Y_train\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X_train[18].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Image de : {}\".format(Y_train[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2.0\n",
      "niveaux de gris :  2001\n"
     ]
    }
   ],
   "source": [
    "# analyse des valeurs min et max, recherche du nombre de niveaux de gris dans les images:\n",
    "print(X_train.min(),X_train.max() )\n",
    "print(\"niveaux de gris : \", len(np.unique(X_train))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Apprentissage et évaluation d'un modèle gaussien naïf\n",
    "\n",
    "## A1- Maximum de vraisemblance \n",
    "\n",
    "Nous allons étudier la distribution de probabilité des teintes de gris des images (en fait, nous allons étudier sa fonction de densité car on travaille sur des variables aléatoires continues) . Nous allons faire l'hypothèse (certes un peu forte mais tellement pratique) que, dans chaque classe, les teintes des pixels sont mutuellement indépendantes. \n",
    "\n",
    "Autrement dit, si $X_i, i\\in \\{0,...,255\\}$ représente la variable aléatoire \"intensité de gris du ième pixel\", alors $p(X_0,…,X_{255})$ représente la fonction de densité des teintes de gris des images de la classe et: \n",
    "\n",
    "$$p(X_0,,…,X_{255})=\\prod_{i=0}^{255} p(X_i)$$\n",
    "\n",
    "Ainsi, en choisissant au hasard une image dans l'ensemble de toutes les images possibles de la classe, si celle-ci correspond au tableau `np.array([x_0,...,x_255])`, où les $x_i$ sont des nombres réels compris entre 0 et 2, alors la valeur de la fonction de densité de l'image est égale à $p(x_0,...,x_{255}) = \\prod^{255}_{i=0}p(x_i)$. \n",
    "\n",
    "Nous allons de plus supposer que chaque $X_i$ suit une distribution normale de paramètres $(μ_i,σ^2_i)$. Autrement dit, $$\\forall i\\in\\{0,...,255\\}, X_i \\sim {\\cal N}(μ_i,σ^2_i)$$ \n",
    "\n",
    "Par maximum de vraisemblance, estimez, pour une classe donnée, l'ensemble des paramètres $(μ_0,…,μ_{255})$ et $(σ^2_0,…,σ^2_{255})$ pour chaque classe (chiffre de 0 à 9). Pour cela, écrivez une fonction `learnML_parameters : float np.array x float np.array -> float np.array x float np.array` qui, étant donné le tableau d'images , renvoie un couple de tableaux, le premier élément du couple correspondant à l'ensemble des $μ_i$ et le 2ème à l'ensemble des $σ^2_i$. C'est-à-dire que `learnML_parameters` renverra deux matrices:\n",
    "$$ mu \\in \\mathbb R^{10 \\times 256}, sig \\in \\mathbb R^{10 \\times 256}$$\n",
    "\n",
    "* mu contient les moyennes des 256 pixels pour les 10 classes\n",
    "* std contient les écarts-types des 256 pixels pour les 10 classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnML_parameters(X,Y):\n",
    "    mu = np.zeros((10,256))\n",
    "    sig = np.zeros((10,256))\n",
    "\n",
    "    for i in range(10):\n",
    "        mu[i] = X[Y==i].mean(0)\n",
    "        sig[i] = np.sqrt(X[Y==i].var(0))\n",
    "\n",
    "    return mu,sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "mu,sig = learnML_parameters ( X_train, Y_train )\n",
    "print(mu.shape, sig.shape) # doit donner (10, 256) (10, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: pour la classe 0, les paramètres doivent être les suivants\n",
    "```\n",
    "mu[0]=\n",
    "[1.53774208e-03 4.46785940e-03 1.71216078e-02 6.31194048e-02\n",
    " 1.84061642e-01 4.71391665e-01 8.97640989e-01 1.15019928e+00\n",
    " ...\n",
    " 1.42675380e+00 1.03130694e+00 5.32240296e-01 1.74166387e-01\n",
    " 3.57644515e-02 5.52804884e-03 4.36592998e-04 0.00000000e+00]\n",
    "sig[0]=\n",
    "[5.01596286e-02 7.93695089e-02 1.46489017e-01 2.65522337e-01\n",
    " 4.42306204e-01 6.35148001e-01 7.40462105e-01 7.48387032e-01\n",
    " ...\n",
    " 6.62741331e-01 6.75677391e-01 5.86224763e-01 3.56460503e-01\n",
    " 1.71512333e-01 5.67475697e-02 1.20193571e-02 0.00000000e+00]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.53774208e-03 4.46785940e-03 1.71216078e-02 6.31194048e-02\n",
      " 1.84061642e-01 4.71391665e-01 8.97640989e-01 1.15019928e+00\n",
      " 1.02070900e+00 6.16785408e-01 2.50766353e-01 8.09903122e-02\n",
      " 1.49310824e-02 3.87033274e-03 1.70898437e-04 0.00000000e+00\n",
      " 2.35601434e-03 7.93762565e-03 5.18573940e-02 2.00940178e-01\n",
      " 5.59411980e-01 1.10202446e+00 1.53532559e+00 1.66378367e+00\n",
      " 1.60174400e+00 1.37845195e+00 9.19353768e-01 4.15479248e-01\n",
      " 1.22346858e-01 3.01527050e-02 4.24372534e-03 5.63428995e-06\n",
      " 5.88210737e-03 3.00679919e-02 1.45009354e-01 4.68428296e-01\n",
      " 9.87103163e-01 1.46020945e+00 1.63103905e+00 1.59445846e+00\n",
      " 1.52785712e+00 1.52155705e+00 1.36630499e+00 9.33882722e-01\n",
      " 4.29464169e-01 1.16865928e-01 2.02650169e-02 1.02089895e-03\n",
      " 7.91202062e-03 6.88018163e-02 3.30783411e-01 8.24194929e-01\n",
      " 1.31254975e+00 1.54256605e+00 1.44943446e+00 1.21191395e+00\n",
      " 1.09220056e+00 1.22655949e+00 1.39070742e+00 1.27821441e+00\n",
      " 8.46682745e-01 3.48925595e-01 8.07226924e-02 4.64439750e-03\n",
      " 1.59532081e-02 1.76675445e-01 6.07781794e-01 1.12757141e+00\n",
      " 1.46523519e+00 1.45472469e+00 1.13856317e+00 8.10338934e-01\n",
      " 6.26168286e-01 7.76955398e-01 1.10779727e+00 1.32851374e+00\n",
      " 1.16676063e+00 6.86548686e-01 2.41357803e-01 2.81289553e-02\n",
      " 4.81442913e-02 3.73752078e-01 8.81483647e-01 1.31949916e+00\n",
      " 1.46700523e+00 1.23718114e+00 8.16962582e-01 4.43474916e-01\n",
      " 2.80405642e-01 4.08021647e-01 7.81619032e-01 1.17122113e+00\n",
      " 1.27515733e+00 9.72332353e-01 4.74029267e-01 8.55221959e-02\n",
      " 1.30783142e-01 5.93982138e-01 1.07686306e+00 1.39894059e+00\n",
      " 1.36844099e+00 9.74245539e-01 5.33412071e-01 2.15832907e-01\n",
      " 1.06282689e-01 1.88639261e-01 5.18731675e-01 9.65949319e-01\n",
      " 1.24726249e+00 1.12132596e+00 6.89466858e-01 1.96154590e-01\n",
      " 2.50674651e-01 7.61315399e-01 1.19695898e+00 1.38864862e+00\n",
      " 1.19971341e+00 7.48517123e-01 3.30572606e-01 9.84733976e-02\n",
      " 4.29241342e-02 1.03367730e-01 3.87229277e-01 8.44056198e-01\n",
      " 1.20012881e+00 1.18425086e+00 8.20222630e-01 3.08674699e-01\n",
      " 3.58261634e-01 8.62190202e-01 1.25563738e+00 1.34673373e+00\n",
      " 1.07142879e+00 5.89123140e-01 1.96728277e-01 4.28680832e-02\n",
      " 1.60351829e-02 7.26840328e-02 3.45407532e-01 8.19457636e-01\n",
      " 1.19289312e+00 1.21496732e+00 8.84999523e-01 3.79906737e-01\n",
      " 3.87331813e-01 9.06482830e-01 1.29035945e+00 1.31940006e+00\n",
      " 9.78757769e-01 4.76966465e-01 1.27168587e-01 2.11923134e-02\n",
      " 1.44063591e-02 8.57732477e-02 3.76648466e-01 8.87929238e-01\n",
      " 1.23895217e+00 1.25035519e+00 8.86075297e-01 3.57954944e-01\n",
      " 3.26138273e-01 8.93522235e-01 1.31510628e+00 1.35238794e+00\n",
      " 9.61461921e-01 4.39577541e-01 1.13927428e-01 3.84975505e-02\n",
      " 5.36327846e-02 1.69787235e-01 5.42599817e-01 1.06182197e+00\n",
      " 1.37321399e+00 1.25057057e+00 8.18406790e-01 2.61721288e-01\n",
      " 1.82330468e-01 7.59475951e-01 1.28679207e+00 1.44958046e+00\n",
      " 1.10688967e+00 5.57203861e-01 2.14130381e-01 1.47069378e-01\n",
      " 2.15676089e-01 4.32815974e-01 8.96862446e-01 1.36377634e+00\n",
      " 1.49075578e+00 1.15939639e+00 6.22067020e-01 1.26992220e-01\n",
      " 5.84152687e-02 4.67427550e-01 1.09806340e+00 1.51210615e+00\n",
      " 1.42226714e+00 9.41197788e-01 5.57709665e-01 4.99719957e-01\n",
      " 6.56042283e-01 1.00399766e+00 1.40647827e+00 1.61266601e+00\n",
      " 1.41656614e+00 8.81148097e-01 3.21861387e-01 3.67738419e-02\n",
      " 1.09871555e-02 1.48898601e-01 6.49790437e-01 1.29661503e+00\n",
      " 1.64543706e+00 1.56182002e+00 1.31738978e+00 1.25782812e+00\n",
      " 1.39819160e+00 1.60791875e+00 1.72751589e+00 1.54867872e+00\n",
      " 1.01832667e+00 4.19518357e-01 9.27781289e-02 7.52478765e-03\n",
      " 2.67797390e-03 2.13532309e-02 1.63836169e-01 6.27896414e-01\n",
      " 1.26470542e+00 1.69852879e+00 1.80189263e+00 1.79891885e+00\n",
      " 1.80963883e+00 1.76736086e+00 1.51130342e+00 9.40219832e-01\n",
      " 3.74622653e-01 8.96866275e-02 1.24228554e-02 1.88855453e-03\n",
      " 7.41913845e-05 1.44583295e-03 1.03138830e-02 7.97420072e-02\n",
      " 3.19437704e-01 7.96441981e-01 1.28306524e+00 1.52049088e+00\n",
      " 1.42675380e+00 1.03130694e+00 5.32240296e-01 1.74166387e-01\n",
      " 3.57644515e-02 5.52804884e-03 4.36592998e-04 0.00000000e+00] [5.01596286e-02 7.93695089e-02 1.46489017e-01 2.65522337e-01\n",
      " 4.42306204e-01 6.35148001e-01 7.40462105e-01 7.48387032e-01\n",
      " 7.52036960e-01 6.78162781e-01 4.81813622e-01 2.95993695e-01\n",
      " 1.02298252e-01 6.82956225e-02 3.69197145e-03 0.00000000e+00\n",
      " 5.53305148e-02 9.36063684e-02 2.40012769e-01 4.83422217e-01\n",
      " 7.27502091e-01 8.01985000e-01 6.94079513e-01 6.09677496e-01\n",
      " 6.52843815e-01 7.58749067e-01 8.06674659e-01 6.41779078e-01\n",
      " 3.75508554e-01 1.82421873e-01 5.60909703e-02 1.83784976e-04\n",
      " 9.07390154e-02 1.92883673e-01 4.16989953e-01 7.07690582e-01\n",
      " 8.35158840e-01 7.30403526e-01 6.28008151e-01 6.32851408e-01\n",
      " 6.86100539e-01 6.71979869e-01 7.51457414e-01 8.24431822e-01\n",
      " 6.63627535e-01 3.74208629e-01 1.38194178e-01 2.98619157e-02\n",
      " 9.45533790e-02 2.82750058e-01 6.06158973e-01 8.42184682e-01\n",
      " 8.02525637e-01 6.80684430e-01 7.48069966e-01 8.29618901e-01\n",
      " 8.54595560e-01 8.13916791e-01 7.25657326e-01 7.80928249e-01\n",
      " 8.29105508e-01 6.20032814e-01 3.01234018e-01 5.58154512e-02\n",
      " 1.09365871e-01 4.41834837e-01 7.86403336e-01 8.54671841e-01\n",
      " 7.25871029e-01 7.49769833e-01 8.60018826e-01 8.48475760e-01\n",
      " 7.93461173e-01 8.30151279e-01 8.38238904e-01 7.46830716e-01\n",
      " 8.23250136e-01 8.07749355e-01 5.21476656e-01 1.51179416e-01\n",
      " 1.93296940e-01 6.43519638e-01 8.66847326e-01 7.99175192e-01\n",
      " 7.32236741e-01 8.36613090e-01 8.58973603e-01 7.10036806e-01\n",
      " 5.93002877e-01 6.76919355e-01 8.31300490e-01 8.22357229e-01\n",
      " 7.87742805e-01 8.57211603e-01 7.19108684e-01 2.69220701e-01\n",
      " 3.32313804e-01 7.92583272e-01 8.69718115e-01 7.69382790e-01\n",
      " 7.94654102e-01 8.64282887e-01 7.76566173e-01 5.26547832e-01\n",
      " 3.76112150e-01 4.76751198e-01 7.55143627e-01 8.53824054e-01\n",
      " 7.91149389e-01 8.39106726e-01 8.31564203e-01 4.23639743e-01\n",
      " 4.87032030e-01 8.63470062e-01 8.47748200e-01 7.72816355e-01\n",
      " 8.52947815e-01 8.56126914e-01 6.26520525e-01 3.57070009e-01\n",
      " 2.32239243e-01 3.50765435e-01 6.85159974e-01 8.53280525e-01\n",
      " 8.21682300e-01 8.23020619e-01 8.73898674e-01 5.52603454e-01\n",
      " 6.01596881e-01 8.84913792e-01 8.23667880e-01 7.97195327e-01\n",
      " 8.79116478e-01 8.04003126e-01 4.88515527e-01 2.33873563e-01\n",
      " 1.32954990e-01 2.82824021e-01 6.47546729e-01 8.55150837e-01\n",
      " 8.32743227e-01 8.13760126e-01 8.79500639e-01 6.23278481e-01\n",
      " 6.27274788e-01 8.87553616e-01 8.08346650e-01 7.99217941e-01\n",
      " 8.83241286e-01 7.40576048e-01 3.95873214e-01 1.58194876e-01\n",
      " 1.35774498e-01 3.17394838e-01 6.64478692e-01 8.69441926e-01\n",
      " 8.24799842e-01 8.14857118e-01 8.75637883e-01 5.99084617e-01\n",
      " 5.60878494e-01 8.79172781e-01 7.99994274e-01 7.79500355e-01\n",
      " 8.71300238e-01 7.07469723e-01 3.70424796e-01 2.22900094e-01\n",
      " 2.61840203e-01 4.53336326e-01 7.48030848e-01 8.66036662e-01\n",
      " 7.69580365e-01 8.21516759e-01 8.58901592e-01 4.99634590e-01\n",
      " 3.90619385e-01 8.34941475e-01 8.17641589e-01 7.24679551e-01\n",
      " 8.40919298e-01 7.59144096e-01 5.11722843e-01 4.41270048e-01\n",
      " 5.16084855e-01 6.84294249e-01 8.42083832e-01 7.76860627e-01\n",
      " 7.07485281e-01 8.39049325e-01 7.73085343e-01 3.34022719e-01\n",
      " 2.04963592e-01 6.81793854e-01 8.40705264e-01 6.82730699e-01\n",
      " 7.26315544e-01 8.23864229e-01 7.46543700e-01 7.28041059e-01\n",
      " 7.90768951e-01 8.23062208e-01 7.65169592e-01 6.35267424e-01\n",
      " 7.38940651e-01 8.33830774e-01 5.75147368e-01 1.70537311e-01\n",
      " 9.87858616e-02 3.81298193e-01 7.51553287e-01 7.80270482e-01\n",
      " 5.63772865e-01 6.42284817e-01 7.48036762e-01 7.75665140e-01\n",
      " 7.32949180e-01 6.31842594e-01 5.10614267e-01 6.55642504e-01\n",
      " 8.07719344e-01 6.34404155e-01 3.08036725e-01 7.70031201e-02\n",
      " 4.28491533e-02 1.49241169e-01 3.88664918e-01 7.09137364e-01\n",
      " 7.47600259e-01 5.37788720e-01 4.69614715e-01 4.75974793e-01\n",
      " 4.70450663e-01 5.17338109e-01 6.74591782e-01 7.68727058e-01\n",
      " 5.82843252e-01 2.99680167e-01 9.71493362e-02 5.02788596e-02\n",
      " 2.30063923e-03 3.19935119e-02 8.28517967e-02 2.53333160e-01\n",
      " 4.80454805e-01 6.58647918e-01 6.69771998e-01 6.43217647e-01\n",
      " 6.62741331e-01 6.75677391e-01 5.86224763e-01 3.56460503e-01\n",
      " 1.71512333e-01 5.67475697e-02 1.20193571e-02 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(mu[0], sig[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2- Log-vraisemblance d'une image pour une classe\n",
    "\n",
    "Écrivez une fonction `log_likelihood : float np.array x float np.array x float np.array -> float` qui, étant donné une image (donc un tableau de 256 nombres réels) et un couple de paramètres `( array ( [μ0,…,μ255] ), array ( [σ20,…,σ255] ) )`, renvoie la log-vraisemblance qu'aurait l'image selon cet ensemble de $μ_i$ et $σ_i$ (correspondant à une classe de chiffre). Rappelez-vous que (en mettant $-\\frac{1}{2}$ en facteur) : \n",
    "\n",
    "$$\\log(p(x_0,\\cdots,x_{255})=\\sum_{i=0}^{255} \\log p(x_i)=-\\frac{1}{2}\\sum_{i=0}^{255} \\left[ \\log(2\\pi \\sigma^2_i) + \\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\right]$$\n",
    "\n",
    "Notez que le module `np` contient une constante `np.pi` ainsi que toutes les fonctions mathématiques classiques directement applicables sur des vecteurs. Vous pouvez donc éventuellement coder la ligne précédente sans boucle, en une ligne.\n",
    "\n",
    "**Attention**: dans la matrice `sig` calculée dans la question précédente, pour certains pixels de certaines classes, la valeur de $σ^2$ est égale à $0$ (toutes les images de la base d'apprentissage avaient exactement la même valeur sur ce pixel). \n",
    "* cette valeur pose problème dans le calcul précédent (division par 0)\n",
    "* Réfléchir à différente manière de traiter ce problème:\n",
    " * faible valeur par défaut de $\\sigma$ reflétant une variance très faible mais évitant la division par 0 (usage de  `np.maximum`par exemple)\n",
    " * vraisemblance de 1 pour le ou les pixels impactés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilisera dans le suite le paramètre defeps: \n",
    "#    positif, il donne la valeur minimale d'écart type\n",
    "#    = -1, il faut prendre une vraisemblance de 1 pour les pixels concernés\n",
    "mu,sig = learnML_parameters ( X_train, Y_train )\n",
    "\n",
    "def log_likelihood(img, mu, sig, defsig = 1e-5):\n",
    "    sig[sig==0]+=defsig\n",
    "    return (-1/2) * np.sum( np.log(2 * np.pi * (sig**2)) + (((img - mu)**2)/(sig**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.69963035168726\n",
      "[-90.69963035168726, -231211311074.5327, -364.8317101985202, -487.01085544875843, -513.128064745155, -387.75946984198, -59610.117733618186, -75567222244.77489, -271.980542616389, -857252055.4774221]\n"
     ]
    }
   ],
   "source": [
    "print(log_likelihood(X_train[0], mu[0], sig[0],1e-5)) \n",
    "# vraisemblance de l'image 0 selon les paramètres de la classe 0\n",
    "\n",
    "print([log_likelihood(X_train[0], mu[i], sig[i],1e-5) for i in range(10)]) \n",
    "# vraisemblance de l'image 0 pour toutes les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : le code ci-dessus avec une valeur par défaut de $1e-5$ pour les sigmas nuls doit donner:\n",
    "```\n",
    "-90.69963035168726\n",
    "```\n",
    "puis pour toutes les classes:\n",
    "```\n",
    "[-90.69963035168726, -231211311074.5327, -364.8317101985202, -487.01085544875843, -513.128064745155, -387.75946984198, -59610.117733618186, -75567222244.77489, -271.980542616389, -857252055.4774221]\n",
    "```\n",
    "\n",
    "Avec une vraisemblance de 1 pour les pixels problématiques:\n",
    "```\n",
    "[-111.88760421521835, -1716629080.989729, -364.83171019852006, -487.01085544875855, -544.9100255404516, -387.7594698419803, -59747.8395637312, -581523.2639945432, -303.762503411686, -13497.825910916881]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3- Classification d'une image\n",
    "Écrire une fonction `classify_image : float np.array x float np.array x float np.array -> int` qui, étant donnée une image et l'ensemble de paramètres déterminés dans les questions précédentes, renvoie la classe la plus probable de l'image, c'est-à-dire celle dont la log-vraisemblance est la plus grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img, mu, sig, defeps=1e-5):\n",
    "        return np.argmax([log_likelihood(img, mu[i], sig[i], defsig = 1e-5) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "classify_image(X_train[0], mu, sig, -1)\n",
    "# l'image 0 est de la classe 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4- Classification de toutes les images\n",
    "Écrire une fonction `classify_all_images : float np.array x float np.array x float np.array -> float np.array` qui, étant donné un tableau $X$ des images ($N \\times 256$) et l'ensemble de paramètres déterminés dans les questions précédentes, renvoie un tableau $\\hat Y$ qui donne la prédiction de classe pour toutes les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_images(X, mu, sig, defeps=1e-5):\n",
    "    return [classify_image(X[i],mu,sig)for i in range(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 7, 8, 2, 5, 6, 0, 9, 0, 7, 6, 0, 6, 6, 5, 2, 1, 6, 9, 0, 6, 5, 9, 8, 4, 0, 7, 6, 5, 4, 4, 2, 7, 6, 6, 6, 2, 1, 1, 8, 1, 1, 6, 0, 3, 1, 1, 8, 0, 7, 2, 5, 0, 2, 9, 1, 2, 0, 8, 6, 0, 6, 9, 7, 7, 9, 1, 3, 6, 1, 0, 0, 6, 6, 2, 1, 3, 9, 0, 0, 5, 9, 6, 2, 1, 0, 1, 0, 8, 3, 9, 0, 7, 1, 5, 0, 0, 0, 2, 6, 8, 1, 7, 9, 3, 0, 7, 2, 2, 0, 0, 1, 8, 2, 0, 0, 1, 9, 0, 9, 3, 7, 1, 1, 8, 5, 0, 0, 9, 0, 1, 2, 1, 7, 1, 9, 1, 0, 3, 6, 6, 6, 6, 7, 0, 8, 2, 8, 2, 0, 1, 7, 9, 0, 2, 0, 3, 8, 0, 7, 7, 0, 8, 8, 1, 8, 2, 8, 5, 7, 2, 7, 0, 8, 0, 2, 6, 6, 0, 1, 0, 9, 2, 9, 9, 1, 3, 1, 0, 5, 1, 9, 2, 4, 0, 2, 1, 0, 3, 9, 1, 7, 9, 9, 7, 0, 7, 1, 9, 1, 0, 9, 9, 6, 1, 2, 1, 0, 7, 1, 8, 0, 3, 1, 9, 2, 0, 8, 9, 6, 7, 8, 0, 6, 9, 1, 9, 9, 3, 7, 7, 8, 6, 1, 9, 9, 7, 1, 6, 7, 9, 3, 3, 1, 8, 2, 8, 8, 2, 9, 8, 8, 6, 7, 1, 7, 1, 5, 4, 2, 9, 8, 0, 9, 0, 1, 1, 6, 2, 9, 0, 7, 9, 5, 6, 3, 7, 6, 2, 8, 8, 1, 0, 6, 9, 3, 6, 0, 2, 0, 9, 0, 5, 0, 0, 1, 1, 6, 8, 2, 6, 0, 6, 6, 1, 7, 7, 8, 8, 0, 6, 3, 1, 1, 2, 2, 7, 0, 8, 0, 2, 2, 8, 0, 6, 7, 6, 9, 1, 7, 6, 6, 1, 9, 1, 9, 1, 1, 6, 7, 6, 1, 0, 3, 7, 7, 1, 3, 7, 6, 6, 7, 0, 1, 9, 9, 7, 5, 8, 7, 9, 0, 9, 1, 7, 1, 2, 7, 6, 1, 6, 6, 3, 5, 3, 9, 4, 9, 2, 9, 7, 0, 6, 3, 7, 4, 6, 1, 9, 4, 0, 1, 8, 9, 4, 1, 8, 1, 8, 8, 1, 2, 7, 0, 6, 0, 8, 0, 4, 9, 6, 7, 2, 9, 7, 7, 0, 3, 8, 1, 2, 9, 0, 2, 6, 4, 9, 5, 8, 2, 1, 5, 1, 2, 1, 3, 9, 6, 6, 1, 5, 0, 6, 0, 5, 1, 9, 1, 2, 7, 8, 0, 9, 9, 7, 6, 1, 0, 8, 3, 7, 6, 6, 1, 7, 9, 3, 7, 9, 8, 6, 0, 8, 9, 2, 7, 0, 3, 9, 6, 6, 8, 1, 7, 8, 9, 1, 7, 0, 8, 6, 0, 2, 0, 3, 7, 2, 0, 3, 0, 1, 7, 1, 2, 1, 7, 2, 1, 7, 7, 7, 8, 4, 2, 8, 0, 6, 9, 6, 1, 8, 1, 6, 2, 2, 6, 0, 1, 8, 3, 6, 0, 2, 7, 9, 1, 0, 0, 2, 9, 3, 1, 7, 0, 9, 1, 0, 1, 7, 9, 1, 8, 1, 6, 5, 6, 0, 8, 2, 8, 1, 8, 9, 8, 0, 1, 3, 3, 3, 7, 8, 7, 5, 2, 7, 9, 4, 6, 4, 0, 7, 0, 8, 1, 2, 6, 7, 9, 2, 8, 4, 2, 6, 6, 6, 0, 4, 9, 6, 8, 9, 4, 6, 9, 0, 9, 7, 6, 7, 0, 9, 0, 6, 5, 2, 8, 6, 8, 7, 2, 5, 0, 7, 7, 7, 8, 2, 7, 0, 0, 1, 2, 9, 9, 8, 7, 4, 1, 7, 6, 0, 8, 1, 2, 9, 8, 1, 0, 3, 7, 6, 0, 2, 0, 3, 3, 9, 1, 7, 7, 5, 6, 8, 7, 9, 1, 0, 9, 5, 6, 7, 6, 9, 0, 2, 4, 1, 7, 1, 1, 5, 6, 1, 7, 7, 0, 8, 6, 1, 3, 4, 9, 9, 7, 6, 8, 6, 2, 7, 7, 9, 5, 0, 7, 6, 6, 0, 0, 7, 1, 8, 6, 6, 2, 1, 1, 5, 7, 3, 8, 6, 6, 7, 7, 1, 7, 8, 6, 1, 7, 6, 0, 7, 3, 1, 5, 3, 2, 7, 9, 0, 6, 4, 9, 7, 2, 0, 8, 7, 9, 2, 7, 7, 0, 1, 9, 6, 3, 6, 0, 1, 6, 6, 8, 7, 7, 1, 7, 2, 0, 6, 0, 1, 3, 2, 3, 8, 8, 1, 1, 8, 7, 1, 0, 9, 9, 6, 3, 2, 9, 7, 6, 6, 8, 8, 3, 7, 6, 9, 7, 8, 6, 5, 5, 6, 1, 1, 6, 6, 5, 0, 0, 8, 1, 7, 7, 3, 9, 0, 5, 0, 1, 6, 6, 1, 0, 1, 1, 6, 8, 8, 0, 5, 7, 8, 7, 3, 5, 7, 0, 8, 9, 1, 9, 7, 0, 2, 8, 4, 7, 9, 9, 6, 6, 2, 6, 3, 6, 9, 1, 7, 1, 9, 7, 7, 7, 0, 6, 0, 1, 4, 7, 7, 5, 0, 0, 7, 9, 6, 0, 8, 8, 9, 2, 3, 2, 2, 1, 7, 0, 8, 3, 3, 5, 0, 1, 9, 0, 1, 0, 0, 1, 1, 7, 6, 0, 7, 0, 0, 2, 9, 2, 3, 9, 5, 9, 7, 0, 6, 4, 8, 5, 1, 3, 6, 9, 1, 0, 1, 6, 0, 9, 7, 2, 4, 8, 2, 0, 6, 0, 0, 1, 7, 0, 0, 1, 1, 0, 0, 5, 7, 5, 0, 1, 0, 7, 0, 6, 7, 6, 6, 8, 8, 6, 7, 7, 6, 0, 9, 1, 0, 8, 1, 1, 4, 3, 5, 7, 7, 1, 2, 5, 5, 2, 6, 0, 9, 1, 8, 0, 7, 9, 9, 6, 2, 8, 8, 0, 2, 8, 8, 0, 1, 7, 1, 9, 6, 0, 9, 0, 0, 0, 9, 9, 6, 8, 1, 9, 4, 0, 7, 7, 3, 2, 1, 0, 7, 8, 9, 7, 1, 3, 9, 6, 1, 9, 0, 7, 3, 9, 9, 9, 1, 7, 8, 7, 1, 8, 7, 3, 6, 1, 1, 0, 2, 8, 5, 7, 2, 7, 0, 0, 6, 7, 0, 0, 6, 7, 4, 2, 2, 0, 8, 7, 9, 8, 3, 5, 6, 8, 1, 0, 1, 9, 8, 9, 1, 7, 0, 1, 1, 0, 1, 6, 5, 9, 9, 2, 6, 2, 6, 3, 6, 8, 0, 5, 3, 8, 6, 3, 7, 1, 7, 6, 9, 3, 6, 2, 6, 0, 1, 9, 7, 1, 4, 3, 1, 6, 6, 1, 9, 0, 5, 1, 7, 2, 8, 5, 7, 1, 2, 9, 9, 0, 6, 6, 5, 9, 6, 3, 1, 7, 7, 1, 8, 3, 9, 8, 1, 6, 2, 8, 4, 2, 9, 7, 6, 8, 6, 7, 6, 9, 4, 1, 0, 8, 5, 7, 9, 6, 4, 0, 6, 6, 8, 5, 7, 0, 6, 0, 9, 7, 2, 7, 1, 9, 6, 6, 5, 9, 0, 7, 1, 7, 3, 1, 6, 8, 8, 3, 8, 6, 1, 0, 1, 1, 6, 7, 1, 0, 8, 8, 9, 9, 5, 7, 7, 0, 8, 9, 4, 2, 1, 6, 7, 1, 8, 6, 3, 1, 3, 2, 7, 9, 7, 8, 9, 6, 1, 5, 7, 0, 8, 6, 1, 9, 6, 1, 5, 7, 8, 9, 7, 1, 0, 0, 6, 8, 7, 6, 9, 7, 1, 0, 7, 3, 0, 8, 7, 1, 2, 6, 7, 9, 5, 6, 2, 9, 6, 1, 1, 6, 0, 2, 9, 4, 3, 5, 6, 6, 7, 2, 0, 9, 1, 2, 5, 6, 2, 7, 2, 7, 1, 0, 8, 3, 0, 5, 1, 5, 7, 6, 0, 4, 1, 8, 5, 0, 2, 7, 7, 1, 2, 1, 7, 6, 6, 5, 6, 2, 6, 6, 2, 1, 1, 6, 2, 1, 1, 2, 1, 9, 8, 4, 4, 1, 8, 9, 0, 9, 0, 9, 2, 6, 0, 8, 0, 1, 2, 9, 9, 2, 1, 6, 5, 3, 9, 1, 6, 3, 1, 7, 6, 8, 9, 6, 7, 7, 1, 5, 1, 4, 0, 6, 8, 9, 1, 7, 2, 9, 6, 0, 1, 1, 8, 9, 7, 3, 3, 2, 1, 3, 8, 0, 1, 7, 9, 0, 8, 8, 7, 6, 9, 9, 2, 9, 4, 3, 2, 3, 9, 6, 2, 3, 9, 7, 4, 7, 9, 7, 1, 3, 5, 9, 9, 7, 7, 7, 2, 7, 8, 7, 1, 5, 7, 7, 0, 8, 9, 7, 7, 8, 5, 6, 7, 1, 7, 3, 8, 7, 5, 6, 7, 4, 9, 7, 1, 1, 7, 7, 7, 0, 1, 0, 0, 1, 0, 6, 5, 9, 9, 6, 7, 3, 9, 1, 6, 6, 3, 0, 2, 0, 1, 5, 0, 0, 9, 0, 3, 2, 8, 3, 7, 5, 8, 0, 1, 1, 8, 6, 6, 0, 1, 7, 1, 9, 6, 6, 1, 9, 9, 7, 8, 9, 7, 7, 1, 6, 0, 0, 0, 2, 4, 1, 2, 1, 0, 8, 3, 6, 6, 6, 9, 0, 2, 7, 5, 2, 0, 9, 0, 8, 9, 4, 7, 0, 0, 0, 0, 8, 2, 0, 7, 9, 7, 6, 9, 6, 2, 1, 7, 3, 1, 6, 7, 6, 0, 7, 6, 3, 6, 1, 1, 1, 6, 8, 7, 6, 0, 9, 1, 6, 6, 6, 6, 0, 5, 9, 7, 7, 3, 6, 9, 0, 1, 6, 0, 0, 6, 2, 8, 2, 0, 6, 5, 1, 0, 9, 1, 6, 4, 1, 0, 1, 0, 0, 0, 6, 1, 1, 6, 9, 3, 2, 7, 1, 0, 9, 1, 0, 6, 7, 8, 5, 1, 8, 1, 9, 3, 1, 7, 7, 2, 1, 3, 7, 2, 6, 4, 6, 1, 0, 5, 9, 9, 2, 0, 9, 2, 3, 7, 3, 0, 3, 8, 1, 0, 9, 1, 6, 3, 9, 6, 1, 1, 6, 2, 8, 1, 7, 6, 3, 1, 5, 2, 5, 1, 6, 8, 6, 1, 6, 0, 0, 5, 7, 3, 2, 6, 6, 2, 1, 1, 3, 6, 7, 2, 6, 2, 6, 7, 8, 2, 6, 2, 1, 8, 7, 7, 0, 0, 9, 8, 1, 6, 8, 9, 8, 0, 0, 1, 1, 7, 8, 8, 0, 7, 7, 8, 6, 0, 8, 4, 6, 1, 6, 5, 2, 2, 9, 6, 5, 7, 7, 1, 1, 2, 8, 9, 8, 1, 9, 6, 6, 6, 0, 9, 8, 2, 7, 6, 3, 3, 6, 5, 8, 0, 1, 9, 6, 7, 7, 9, 0, 4, 6, 8, 7, 6, 0, 0, 8, 1, 9, 0, 7, 1, 6, 7, 8, 0, 1, 1, 0, 0, 4, 7, 9, 7, 7, 9, 7, 0, 0, 6, 7, 1, 8, 6, 8, 1, 8, 7, 6, 0, 2, 2, 8, 7, 2, 1, 1, 1, 9, 2, 1, 4, 0, 2, 1, 3, 8, 2, 6, 1, 2, 2, 7, 3, 1, 3, 3, 1, 8, 2, 0, 0, 8, 1, 1, 0, 7, 1, 7, 1, 7, 2, 6, 8, 5, 1, 7, 1, 0, 8, 7, 7, 7, 2, 5, 5, 0, 8, 2, 7, 5, 1, 6, 1, 9, 0, 8, 7, 6, 0, 6, 9, 6, 1, 1, 1, 7, 7, 0, 0, 8, 5, 1, 9, 7, 3, 8, 6, 8, 1, 7, 9, 0, 8, 7, 8, 7, 1, 3, 9, 0, 8, 8, 7, 8, 8, 8, 0, 1, 5, 0, 7, 0, 1, 7, 6, 2, 1, 1, 6, 0, 4, 0, 9, 6, 6, 7, 1, 1, 6, 1, 8, 1, 7, 0, 3, 0, 7, 7, 8, 7, 2, 5, 3, 3, 7, 9, 0, 1, 4, 0, 6, 1, 5, 7, 1, 6, 1, 1, 7, 9, 1, 6, 8, 7, 2, 1, 9, 1, 9, 3, 7, 2, 0, 5, 0, 2, 7, 5, 2, 5, 9, 0, 2, 0, 3, 9, 0, 1, 1, 9, 0, 5, 7, 7, 4, 3, 3, 7, 1, 2, 0, 0, 8, 6, 1, 1, 2, 1, 3, 7, 8, 5, 9, 0, 9, 8, 1, 6, 7, 1, 7, 5, 7, 1, 1, 1, 5, 1, 1, 9, 8, 0, 3, 4, 2, 9, 1, 0, 1, 7, 0, 1, 3, 6, 0, 3, 2, 8, 6, 6, 7, 3, 6, 1, 9, 7, 4, 9, 1, 6, 8, 8, 1, 7, 6, 3, 7, 9, 6, 0, 4, 9, 2, 1, 8, 1, 8, 6, 5, 3, 0, 0, 8, 3, 1, 2, 0, 8, 0, 1, 7, 1, 7, 2, 1, 6, 3, 6, 6, 8, 2, 2, 1, 6, 6, 9, 7, 7, 9, 9, 6, 7, 7, 0, 1, 8, 9, 3, 6, 9, 9, 6, 1, 9, 0, 9, 1, 6, 1, 8, 9, 8, 7, 1, 9, 7, 1, 5, 8, 7, 8, 9, 3, 2, 0, 0, 2, 7, 1, 6, 4, 3, 9, 6, 2, 9, 0, 8, 6, 4, 3, 1, 1, 1, 3, 1, 2, 7, 9, 2, 6, 1, 8, 6, 9, 6, 9, 6, 6, 2, 0, 1, 6, 1, 9, 0, 1, 0, 7, 8, 2, 3, 6, 6, 0, 6, 7, 0, 6, 9, 1, 0, 2, 8, 7, 0, 0, 1, 6, 2, 8, 2, 1, 2, 5, 1, 0, 8, 6, 8, 9, 8, 2, 7, 5, 1, 0, 1, 1, 9, 6, 3, 0, 5, 9, 1, 8, 0, 8, 8, 9, 7, 0, 8, 5, 6, 0, 3, 1, 0, 8, 0, 4, 6, 2, 6, 7, 0, 7, 9, 7, 1, 6, 7, 7, 1, 7, 7, 7, 2, 7, 2, 6, 0, 9, 2, 4, 1, 1, 7, 0, 6, 2, 2, 1, 7, 3, 9, 7, 5, 9, 5, 0, 1, 4, 1, 1, 0, 3, 2, 2, 0, 6, 8, 9, 0, 8, 0, 6, 3, 7, 7, 0, 0, 9, 5, 8, 0, 1, 9, 4, 9, 9, 4, 0, 6, 1, 3, 9, 1, 6, 0, 0, 1, 2, 5, 5, 2, 2, 0, 1, 1, 1, 7, 7, 7, 1, 6, 6, 8, 9, 1, 6, 7, 0, 3, 3, 4, 6, 7, 3, 4, 2, 6, 6, 2, 7, 1, 1, 0, 6, 2, 9, 8, 9, 6, 1, 6, 3, 3, 9, 3, 6, 6, 0, 1, 1, 5, 0, 0, 0, 1, 2, 0, 3, 0, 7, 6, 8, 3, 1, 9, 1, 6, 5, 2, 0, 6, 2, 6, 6, 9, 3, 8, 4, 8, 8, 8, 0, 0, 7, 7, 6, 9, 7, 7, 2, 1, 8, 2, 8, 0, 9, 8, 7, 9, 3, 6, 7, 0, 1, 7, 0, 8, 2, 1, 6, 9, 7, 7, 8, 9, 0, 3, 0, 1, 8, 2, 9, 0, 9, 7, 0, 7, 3, 7, 1, 4, 3, 7, 2, 6, 9, 2, 7, 7, 9, 8, 3, 1, 9, 1, 1, 0, 9, 7, 7, 1, 6, 1, 0, 1, 6, 0, 0, 1, 2, 0, 7, 0, 8, 7, 1, 3, 0, 0, 8, 6, 6, 1, 4, 0, 8, 6, 3, 1, 7, 6, 8, 4, 7, 0, 1, 0, 1, 2, 8, 9, 9, 7, 9, 3, 9, 3, 6, 6, 0, 6, 5, 1, 7, 7, 9, 9, 2, 0, 2, 5, 6, 2, 8, 0, 9, 0, 0, 8, 6, 0, 7, 8, 9, 9, 6, 1, 7, 0, 8, 3, 9, 7, 1, 8, 5, 0, 8, 6, 6, 8, 0, 1, 9, 6, 9, 7, 0, 7, 9, 1, 5, 0, 9, 5, 9, 5, 0, 7, 7, 0, 7, 2, 8, 2, 1, 2, 1, 7, 5, 9, 1, 9, 2, 1, 9, 6, 6, 1, 1, 1, 1, 8, 0, 6, 9, 2, 6, 3, 1, 1, 6, 0, 1, 7, 8, 2, 6, 0, 7, 0, 0, 7, 6, 1, 6, 7, 9, 9, 2, 0, 2, 2, 1, 0, 5, 0, 6, 7, 0, 0, 9, 8, 0, 9, 8, 8, 4, 0, 0, 3, 1, 6, 6, 9, 6, 2, 6, 0, 7, 9, 0, 1, 1, 9, 5, 0, 7, 0, 2, 7, 6, 9, 8, 2, 6, 8, 6, 9, 7, 3, 3, 0, 5, 6, 8, 6, 9, 7, 7, 8, 3, 1, 9, 7, 7, 1, 7, 0, 8, 5, 7, 9, 2, 6, 1, 5, 1, 6, 6, 3, 6, 0, 8, 4, 9, 6, 1, 9, 6, 6, 7, 6, 6, 3, 1, 7, 0, 0, 6, 5, 9, 9, 0, 6, 8, 0, 0, 8, 1, 6, 1, 6, 0, 6, 8, 3, 6, 8, 9, 5, 3, 6, 8, 6, 6, 7, 2, 1, 6, 2, 8, 6, 0, 0, 1, 7, 1, 1, 5, 7, 2, 0, 6, 0, 9, 9, 6, 1, 0, 0, 7, 9, 3, 9, 9, 6, 3, 9, 2, 1, 6, 6, 7, 0, 6, 0, 9, 9, 6, 8, 1, 2, 1, 0, 8, 1, 1, 9, 0, 1, 8, 3, 9, 1, 6, 5, 6, 0, 1, 6, 7, 7, 6, 9, 8, 0, 5, 2, 3, 3, 3, 1, 5, 1, 7, 3, 0, 0, 6, 2, 4, 0, 1, 2, 9, 9, 0, 9, 0, 1, 0, 9, 6, 9, 9, 9, 8, 8, 0, 9, 1, 0, 4, 2, 5, 9, 7, 7, 1, 5, 7, 7, 9, 7, 3, 0, 0, 8, 0, 6, 1, 6, 7, 7, 5, 6, 0, 1, 3, 3, 8, 9, 3, 8, 5, 2, 2, 7, 7, 6, 7, 0, 3, 9, 3, 1, 9, 1, 5, 0, 7, 0, 9, 0, 2, 1, 9, 6, 0, 9, 9, 6, 2, 1, 1, 7, 8, 6, 1, 1, 0, 1, 7, 0, 1, 7, 8, 0, 9, 6, 1, 8, 3, 1, 0, 1, 0, 1, 2, 1, 7, 9, 1, 0, 1, 7, 3, 3, 7, 6, 0, 1, 7, 3, 8, 3, 0, 2, 9, 0, 6, 9, 4, 7, 9, 4, 3, 6, 2, 3, 9, 7, 8, 9, 5, 2, 9, 1, 0, 3, 9, 9, 2, 6, 0, 0, 0, 7, 7, 6, 6, 2, 0, 2, 0, 3, 8, 2, 0, 0, 0, 0, 7, 7, 9, 9, 1, 0, 6, 3, 8, 1, 0, 6, 6, 0, 9, 2, 8, 1, 1, 6, 7, 0, 1, 7, 7, 6, 2, 3, 4, 6, 1, 8, 9, 7, 1, 2, 0, 9, 6, 0, 5, 7, 9, 3, 9, 5, 8, 1, 6, 1, 0, 1, 6, 8, 8, 7, 0, 2, 9, 1, 1, 9, 2, 8, 7, 3, 5, 2, 0, 7, 7, 8, 0, 6, 7, 1, 0, 7, 0, 3, 7, 9, 1, 2, 9, 1, 8, 6, 0, 2, 9, 6, 8, 1, 7, 6, 8, 8, 5, 1, 3, 0, 0, 7, 9, 6, 2, 7, 8, 7, 4, 0, 7, 1, 0, 0, 7, 6, 9, 7, 1, 7, 1, 8, 6, 3, 8, 6, 1, 3, 0, 6, 0, 7, 7, 0, 7, 8, 7, 7, 4, 9, 6, 9, 0, 8, 4, 6, 9, 0, 7, 2, 0, 3, 6, 1, 8, 1, 0, 3, 0, 0, 6, 6, 6, 0, 6, 1, 0, 2, 0, 4, 1, 3, 9, 6, 3, 6, 2, 7, 0, 4, 2, 8, 4, 7, 0, 2, 1, 9, 0, 7, 8, 0, 0, 0, 9, 7, 9, 2, 6, 0, 1, 8, 1, 2, 5, 9, 8, 5, 0, 1, 3, 0, 9, 7, 8, 0, 9, 0, 0, 9, 7, 6, 6, 7, 6, 0, 2, 0, 7, 5, 6, 3, 8, 9, 1, 7, 8, 8, 6, 0, 7, 1, 0, 7, 6, 6, 0, 2, 1, 1, 0, 2, 7, 1, 6, 0, 1, 1, 3, 7, 2, 7, 1, 9, 2, 1, 8, 7, 0, 4, 9, 0, 8, 5, 1, 7, 9, 1, 8, 1, 3, 2, 7, 6, 1, 1, 1, 6, 1, 0, 6, 1, 4, 0, 1, 0, 7, 2, 1, 5, 1, 9, 1, 8, 3, 7, 6, 2, 8, 9, 0, 2, 2, 0, 7, 5, 8, 6, 7, 2, 7, 1, 8, 8, 6, 0, 5, 7, 0, 2, 7, 0, 6, 0, 7, 0, 0, 6, 8, 3, 7, 9, 7, 6, 1, 7, 0, 3, 7, 8, 1, 7, 0, 8, 9, 0, 9, 7, 2, 5, 5, 2, 0, 4, 3, 9, 2, 7, 8, 6, 7, 7, 1, 6, 4, 1, 8, 8, 6, 1, 2, 7, 9, 0, 0, 8, 7, 0, 3, 0, 8, 8, 9, 8, 8, 9, 8, 6, 0, 1, 2, 7, 1, 0, 1, 0, 7, 1, 9, 6, 5, 7, 9, 3, 2, 6, 1, 7, 5, 7, 1, 2, 1, 6, 0, 9, 2, 6, 1, 7, 9, 0, 1, 5, 9, 1, 8, 3, 6, 7, 6, 4, 1, 8, 8, 9, 5, 2, 9, 2, 1, 5, 2, 2, 0, 6, 8, 2, 0, 1, 2, 2, 1, 7, 2, 5, 9, 1, 0, 9, 0, 9, 8, 3, 4, 4, 6, 1, 0, 2, 9, 4, 2, 7, 9, 6, 3, 0, 6, 0, 0, 1, 1, 7, 8, 0, 8, 5, 9, 9, 1, 0, 0, 8, 7, 0, 1, 5, 9, 7, 6, 6, 9, 1, 0, 6, 0, 7, 6, 1, 0, 1, 1, 1, 0, 1, 3, 0, 0, 6, 2, 6, 6, 1, 5, 6, 9, 9, 4, 5, 5, 5, 7, 6, 2, 0, 1, 1, 7, 0, 6, 6, 7, 6, 8, 3, 8, 7, 5, 6, 0, 6, 9, 9, 0, 9, 8, 7, 0, 2, 2, 7, 8, 6, 7, 3, 6, 8, 9, 1, 2, 2, 8, 6, 1, 1, 7, 3, 0, 0, 4, 8, 6, 6, 1, 8, 7, 6, 8, 8, 0, 9, 3, 8, 1, 1, 8, 1, 7, 0, 8, 8, 0, 0, 5, 7, 7, 8, 8, 1, 9, 8, 6, 7, 8, 9, 1, 0, 1, 1, 6, 6, 6, 4, 0, 4, 2, 6, 2, 8, 6, 5, 9, 9, 2, 1, 1, 1, 9, 9, 6, 0, 6, 4, 0, 8, 2, 6, 8, 7, 8, 9, 2, 3, 8, 8, 7, 8, 0, 9, 7, 3, 2, 2, 9, 3, 2, 7, 0, 7, 6, 2, 0, 0, 1, 0, 1, 1, 0, 9, 7, 4, 0, 1, 6, 9, 1, 7, 6, 1, 2, 2, 1, 3, 1, 2, 8, 0, 9, 7, 6, 9, 0, 6, 1, 6, 1, 6, 9, 9, 6, 6, 9, 6, 0, 9, 7, 6, 0, 3, 7, 6, 7, 7, 9, 0, 3, 0, 0, 9, 9, 0, 0, 7, 6, 4, 5, 0, 7, 8, 1, 2, 2, 1, 3, 2, 1, 1, 5, 9, 7, 8, 9, 8, 1, 1, 1, 3, 1, 8, 1, 0, 6, 9, 0, 1, 1, 2, 8, 6, 1, 6, 5, 1, 9, 7, 6, 2, 8, 6, 8, 9, 6, 0, 0, 4, 7, 9, 0, 0, 2, 7, 2, 5, 8, 8, 8, 8, 3, 7, 0, 3, 3, 9, 1, 1, 9, 6, 7, 2, 2, 1, 6, 8, 8, 8, 0, 7, 4, 9, 7, 9, 0, 7, 7, 2, 2, 3, 7, 5, 0, 7, 1, 3, 6, 8, 9, 9, 8, 9, 1, 9, 1, 6, 1, 0, 0, 7, 9, 8, 5, 3, 7, 1, 0, 6, 0, 1, 5, 6, 9, 3, 1, 7, 2, 6, 6, 5, 1, 1, 7, 1, 0, 9, 1, 1, 2, 7, 6, 7, 1, 9, 6, 1, 0, 5, 3, 8, 0, 1, 0, 0, 8, 0, 1, 1, 4, 5, 2, 1, 0, 9, 1, 7, 0, 8, 0, 9, 8, 9, 1, 9, 2, 9, 1, 6, 9, 7, 9, 1, 5, 7, 4, 1, 8, 9, 9, 7, 4, 2, 0, 0, 0, 5, 6, 0, 1, 3, 1, 6, 6, 1, 1, 9, 6, 3, 1, 1, 9, 7, 6, 9, 3, 1, 6, 0, 2, 1, 8, 8, 6, 7, 7, 8, 6, 0, 1, 1, 0, 0, 0, 3, 9, 5, 6, 9, 1, 1, 6, 0, 6, 6, 4, 6, 6, 9, 5, 1, 0, 7, 0, 7, 7, 5, 9, 1, 7, 4, 8, 3, 7, 9, 3, 8, 0, 2, 7, 9, 0, 6, 5, 8, 8, 6, 6, 0, 6, 9, 1, 4, 4, 2, 8, 1, 7, 2, 1, 8, 7, 8, 7, 1, 0, 2, 0, 8, 2, 7, 6, 3, 0, 0, 1, 8, 6, 0, 9, 9, 0, 8, 8, 1, 0, 6, 6, 7, 6, 6, 1, 0, 7, 0, 8, 4, 5, 6, 7, 1, 6, 6, 6, 0, 9, 8, 7, 2, 0, 0, 6, 1, 7, 6, 9, 7, 1, 7, 6, 3, 2, 1, 5, 1, 0, 0, 7, 7, 0, 9, 7, 8, 5, 6, 1, 6, 6, 1, 2, 2, 9, 7, 0, 3, 2, 9, 2, 9, 2, 7, 3, 5, 1, 9, 1, 0, 9, 0, 1, 1, 9, 2, 6, 0, 9, 8, 0, 6, 4, 7, 4, 6, 5, 6, 1, 8, 6, 6, 4, 0, 1, 9, 1, 8, 1, 7, 1, 3, 1, 9, 3, 1, 6, 1, 0, 7, 6, 4, 0, 0, 8, 5, 0, 1, 7, 0, 0, 1, 1, 0, 1, 6, 4, 6, 6, 0, 1, 1, 4, 9, 5, 1, 2, 1, 7, 7, 5, 4, 6, 9, 9, 1, 0, 5, 6, 8, 6, 2, 8, 7, 2, 9, 7, 7, 0, 2, 6, 9, 9, 0, 8, 3, 3, 6, 8, 3, 7, 0, 9, 0, 9, 2, 8, 1, 8, 1, 3, 2, 7, 6, 2, 1, 9, 8, 8, 8, 1, 9, 9, 1, 7, 1, 6, 1, 1, 9, 0, 2, 1, 2, 7, 3, 2, 9, 2, 9, 1, 7, 2, 1, 8, 1, 9, 0, 1, 4, 1, 6, 8, 1, 2, 1, 2, 8, 2, 1, 9, 7, 7, 9, 8, 6, 3, 0, 9, 1, 2, 3, 1, 8, 3, 0, 0, 0, 1, 6, 2, 3, 0, 7, 1, 0, 1, 8, 1, 0, 8, 9, 8, 8, 2, 5, 1, 7, 2, 5, 7, 9, 9, 1, 4, 0, 9, 8, 8, 6, 8, 1, 9, 0, 0, 0, 3, 2, 8, 0, 6, 0, 0, 0, 5, 1, 6, 6, 0, 8, 8, 6, 0, 7, 4, 0, 8, 6, 2, 4, 2, 9, 9, 6, 6, 9, 6, 2, 6, 2, 6, 7, 3, 8, 2, 6, 6, 3, 0, 0, 0, 9, 0, 1, 9, 5, 9, 8, 0, 5, 5, 9, 1, 6, 2, 1, 9, 8, 5, 1, 7, 7, 8, 8, 2, 5, 3, 6, 3, 0, 0, 1, 7, 7, 4, 1, 0, 6, 8, 9, 9, 0, 0, 7, 2, 0, 2, 6, 8, 6, 8, 2, 4, 7, 9, 1, 7, 3, 6, 8, 7, 2, 9, 6, 1, 9, 3, 9, 9, 0, 0, 6, 7, 2, 8, 7, 5, 7, 9, 0, 1, 7, 2, 6, 1, 6, 7, 1, 9, 8, 0, 1, 6, 1, 7, 7, 9, 1, 0, 6, 6, 0, 5, 6, 6, 0, 7, 6, 7, 9, 9, 2, 7, 9, 7, 3, 0, 0, 1, 2, 0, 2, 9, 1, 0, 9, 8, 9, 1, 7, 6, 9, 0, 0, 5, 6, 7, 6, 3, 3, 1, 8, 0, 9, 1, 0, 7, 7, 1, 0, 2, 0, 6, 7, 0, 8, 3, 0, 1, 3, 9, 7, 1, 3, 5, 3, 2, 9, 0, 1, 1, 7, 9, 0, 0, 8, 7, 1, 7, 9, 7, 8, 7, 7, 0, 2, 9, 1, 9, 4, 7, 9, 9, 7, 1, 7, 3, 1, 2, 1, 7, 7, 6, 6, 5, 1, 7, 0, 8, 0, 7, 2, 3, 6, 0, 7, 5, 4, 9, 0, 2, 6, 9, 7, 9, 9, 7, 1, 0, 9, 1, 7, 1, 2, 6, 6, 3, 6, 7, 7, 1, 6, 7, 9, 7, 9, 1, 3, 4, 6, 2, 3, 2, 5, 0, 1, 6, 9, 5, 2, 0, 6, 8, 1, 8, 7, 1, 6, 1, 1, 7, 0, 1, 7, 6, 3, 7, 5, 1, 7, 1, 0, 2, 4, 9, 4, 2, 1, 4, 0, 9, 2, 7, 8, 8, 9, 9, 9, 7, 1, 7, 8, 0, 7, 6, 8, 1, 8, 0, 0, 7, 9, 0, 6, 5, 6, 4, 6, 1, 7, 9, 8, 8, 7, 3, 8, 0, 6, 1, 1, 2, 1, 9, 7, 9, 0, 8, 7, 1, 1, 6, 6, 5, 9, 1, 9, 1, 1, 1, 8, 9, 7, 8, 1, 9, 6, 2, 1, 9, 8, 5, 1, 9, 6, 7, 9, 0, 9, 9, 9, 0, 0, 9, 2, 8, 4, 8, 1, 7, 6, 4, 9, 6, 9, 1, 2, 9, 1, 0, 6, 9, 9, 2, 9, 6, 1, 0, 2, 0, 9, 9, 1, 0, 1, 0, 1, 6, 1, 7, 2, 1, 1, 2, 2, 0, 6, 0, 1, 9, 6, 7, 6, 0, 8, 9, 1, 0, 0, 3, 7, 8, 6, 6, 1, 7, 2, 1, 0, 8, 8, 8, 3, 6, 1, 1, 2, 0, 1, 7, 2, 1, 6, 7, 7, 3, 1, 0, 6, 8, 7, 6, 0, 7, 5, 1, 8, 8, 9, 9, 0, 9, 4, 2, 0, 8, 7, 6, 4, 1, 6, 2, 4, 2, 7, 8, 6, 9, 9, 8, 9, 1, 2, 6, 1, 1, 6, 6, 1, 6, 9, 2, 0, 3, 1, 8, 1, 2, 0, 9, 9, 8, 6, 9, 2, 0, 6, 1, 1, 0, 0, 7, 6, 6, 9, 7, 6, 3, 0, 9, 7, 2, 9, 9, 8, 1, 8, 1, 1, 9, 0, 9, 8, 8, 9, 6, 1, 1, 6, 9, 7, 6, 2, 8, 9, 2, 7, 7, 1, 8, 1, 0, 1, 6, 7, 1, 0, 0, 6, 2, 6, 9, 8, 7, 7, 4, 2, 1, 2, 0, 9, 0, 6, 6, 2, 0, 1, 6, 9, 7, 7, 3, 5, 7, 1, 0, 9, 0, 1, 2, 2, 7, 1, 2, 0, 8, 8, 0, 9, 0, 3, 8, 6, 7, 9, 8, 0, 3, 2, 3, 0, 6, 7, 0, 6, 2, 8, 1, 7, 9, 8, 6, 1, 2, 9, 6, 6, 8, 0, 8, 9, 3, 9, 8, 1, 6, 0, 0, 7, 8, 9, 5, 6, 6, 8, 9, 0, 6, 7, 1, 3, 5, 0, 1, 1, 8, 6, 1, 0, 8, 6, 6, 0, 0, 0, 8, 2, 1, 4, 1, 6, 9, 6, 1, 8, 7, 5, 2, 7, 0, 6, 1, 8, 6, 8, 1, 8, 0, 9, 7, 6, 7, 1, 8, 4, 1, 9, 6, 3, 7, 2, 5, 0, 1, 2, 6, 1, 7, 0, 7, 1, 1, 0, 5, 7, 0, 6, 9, 8, 1, 6, 9, 9, 9, 1, 2, 0, 0, 4, 9, 0, 0, 0, 9, 1, 0, 8, 7, 8, 8, 9, 0, 1, 6, 0, 7, 1, 1, 6, 0, 1, 9, 1, 3, 7, 6, 9, 6, 4, 9, 3, 1, 9, 6, 8, 0, 5, 4, 5, 9, 1, 2, 7, 8, 9, 3, 0, 9, 0, 1, 3, 7, 1, 9, 7, 9, 1, 8, 0, 4, 8, 9, 7, 0, 1, 0, 9, 8, 9, 3, 1, 7, 5, 8, 9, 0, 0, 8, 6, 0, 0, 7, 0, 9, 7, 3, 9, 7, 3, 7, 7, 0, 0, 7, 2, 9, 1, 4, 0, 3, 6, 9, 6, 0, 7, 1, 7, 4, 9, 7, 4, 5, 1, 9, 8, 1, 7, 1, 8, 1, 2, 1, 2, 9, 0, 7, 3, 1, 8, 8, 3, 2, 0, 8, 9, 0, 3, 6, 6, 1, 7, 1, 7, 1, 7, 2, 9, 9, 6, 2, 6, 7, 3, 7, 0, 1, 1, 0, 1, 2, 7, 1, 9, 1, 2, 6, 1, 7, 0, 1, 7, 1, 7, 7, 8, 0, 7, 6, 3, 0, 7, 6, 3, 6, 9, 2, 0, 2, 6, 0, 6, 1, 7, 7, 6, 8, 7, 0, 1, 7, 7, 8, 1, 1, 6, 8, 0, 1, 0, 3, 2, 0, 7, 7, 9, 1, 5, 6, 2, 1, 3, 0, 0, 5, 8, 3, 6, 0, 9, 0, 9, 4, 0, 1, 1, 0, 8, 1, 9, 6, 5, 2, 0, 7, 6, 3, 4, 0, 8, 7, 9, 9, 9, 9, 7, 0, 7, 1, 1, 6, 2, 9, 2, 2, 2, 7, 6, 8, 6, 8, 8, 2, 7, 9, 0, 8, 9, 6, 2, 2, 7, 1, 1, 2, 1, 9, 4, 2, 3, 9, 0, 8, 7, 8, 1, 2, 0, 9, 8, 6, 7, 3, 0, 8, 1, 9, 9, 6, 8, 5, 2, 2, 7, 6, 2, 8, 7, 9, 2, 1, 1, 6, 7, 9, 0, 1, 2, 1, 0, 9, 5, 0, 1, 8, 2, 1, 7, 1, 9, 0, 2, 9, 0, 9, 3, 2, 7, 8, 8, 6, 1, 0, 1, 9, 1, 7, 9, 6, 5, 7, 9, 7, 1, 7, 7, 6, 8, 1, 1, 9, 3, 0, 7, 3, 5, 0, 6, 7, 0, 6, 1, 9, 0, 2, 0, 1, 2, 8, 6, 0, 8, 8, 1, 1, 0, 2, 1, 0, 9, 2, 6, 9, 1, 5, 0, 8, 2, 0, 0, 9, 6, 7, 0, 8, 9, 5, 2, 9, 8, 8, 8, 5, 0, 8, 7, 6, 0, 9, 1, 3, 1, 1, 9, 1, 8, 7, 9, 1, 6, 1, 3, 7, 6, 0, 0, 1, 7, 1, 7, 2, 0, 8, 9, 7, 4, 9, 6, 0, 8, 3, 2, 9, 0, 7, 6, 3, 4, 7, 8, 3, 5, 6, 6, 8, 1, 2, 1, 2, 5, 7, 7, 3, 6, 7, 8, 2, 6, 5, 1, 0, 2, 1, 0, 8, 1, 6, 8, 4, 0, 0, 9, 1, 1, 9, 1, 0, 8, 1, 1, 1, 0, 6, 3, 9, 6, 6, 3, 8, 1, 2, 3, 6, 7, 1, 8, 0, 9, 7, 3, 7, 7, 7, 6, 0, 9, 3, 4, 7, 0, 6, 6, 6, 8, 1, 1, 1, 8, 9, 1, 9, 0, 2, 9, 9, 0, 9, 5, 1, 7, 6, 1, 1, 1, 1, 6, 1, 2, 4, 6, 9, 7, 2, 3, 6, 8, 9, 7, 1, 7, 6, 9, 4, 3, 3, 9, 1, 3, 6, 1, 1, 9, 7, 0, 1, 0, 6, 0, 6, 0, 4, 8, 0, 3, 9, 6, 8, 7, 8, 8, 9, 7, 6, 2, 0, 6, 0, 3, 1, 0, 1, 0, 9, 2, 6, 6, 2, 8, 2, 1, 1, 9, 1, 0, 1, 8, 1, 6, 8, 9, 9, 0, 6, 9, 6, 9, 0, 7, 6, 0, 6, 9, 0, 1, 7, 1, 2, 8, 6, 2, 2, 3, 2, 9, 4, 0, 1, 6, 6, 1, 0, 8, 6, 0, 7, 1, 7, 9, 3, 9, 6, 9, 9, 9, 0, 7, 7, 8, 2, 6, 8, 9, 7, 3, 0, 0, 4, 1, 7, 2, 2, 0, 9, 2, 4, 9, 3, 7, 0, 6, 7, 6, 6, 6, 1, 1, 6, 1, 1, 0, 9, 0, 5, 1, 7, 7, 6, 0, 9, 6, 1, 4, 0, 6, 6, 0, 0, 6, 0, 8, 5, 8, 6, 9, 7, 9, 0, 0, 0, 7, 6, 3, 0, 3, 0, 9, 6, 6, 6, 7, 9, 9, 5, 1, 9, 2, 7, 6, 7, 1, 6, 4, 8, 8, 3, 9, 9, 4, 7, 0, 8, 1, 9, 0, 6, 9, 9, 5, 0, 9, 0, 8, 5, 7, 2, 7, 6, 6, 7, 8, 1, 6, 7, 3, 6, 2, 5, 8, 7, 0, 8, 8, 0, 6, 0, 4, 1, 1, 7, 6, 8, 6, 6, 1, 0, 1, 7, 7, 9, 8, 1, 0, 7, 3, 1, 2, 9, 1, 9, 9, 0, 0, 8, 4, 2, 8, 9, 7, 8, 1, 6, 2, 6, 7, 7, 5, 3, 8, 0, 2, 0, 0, 6, 1, 1, 6, 0, 6, 7, 7, 0, 2, 8, 1, 6, 0, 3, 6, 7, 6, 0, 8, 6, 6, 3, 2, 9, 2, 9, 9, 6, 8, 1, 4, 3, 2, 7, 9, 0, 7, 2, 1, 6, 9, 4, 8, 6, 8, 4, 7, 9, 9, 7, 5, 7, 0, 2, 9, 9, 1, 8, 8, 7, 8, 3, 2, 4, 6, 0, 1, 6, 8, 9, 7, 7, 0, 9, 1, 7, 6, 8, 3, 9, 1, 9, 7, 6, 0, 7, 5, 2, 7, 2, 4, 7, 5, 5, 6, 1, 7, 3, 9, 7, 9, 8, 9, 1, 9, 8, 6, 7, 6, 5, 8, 7, 0, 5, 3, 8, 0, 0, 6, 2, 0, 1, 1, 1, 6, 6, 1, 7, 9, 9, 0, 8, 1, 2, 6, 0, 8, 9, 7, 4, 1, 7, 6, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "Y_train_hat = classify_all_images(X_train, mu, sig, -1)\n",
    "\n",
    "print(Y_train_hat) # doit rendre: [0 9 7 ... 6 3 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5-Matrice de confusion et affichage du résultat des classifications\n",
    "\n",
    "La matrice de confusion est de la forme $C \\times C$ où $C$ est le nombre de classe. Les lignes sont les vraies classes, les colonnes sont les classes prédites. Chaque case (i,j) contient le nombre d'images correspondant à la vraie classe i et à la prédiction j.\n",
    "Si votre classifieur est performant, vous devriez observer des pics sur la diagonale. \n",
    "\n",
    "La fonction `matrice_confusion(Y, Y_hat)` prend en argument un vecteur d'étiquettes réelles et un vecteur de même taille d'étiquettes prédites et retourne la matrice de confusion.\n",
    "\n",
    "Vous devriez obtenir une matrice de la forme:\n",
    "<img src=\"mat_conf_train.png\" title=\"Matrice de confusion\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_confusion(Y, Y_hat):\n",
    "    m=np.zeros((10,10))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        m[int(Y[i])][int(Y_hat[i])]+=1\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonne classification: 0.7135976882324611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffc91677e20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# affichage de la matrice de confusion\n",
    "m = matrice_confusion(Y_train, Y_train_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_train == Y_train_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6- Ensemble d'apprentissage, ensemble de test\n",
    "\n",
    "Dans la procédure que nous avons suivie jusqu'ici, nous avons triché. Les mêmes données servent à apprendre les paramètres et à évaluer le modèle. Evidemment, le modèle est parfaitement adapté et les performances sur-estimées.\n",
    "\n",
    "Afin de réduire ce biais, nous allons maintenant évaluer les performances sur les données de test. Les performances devraient être plus basses... Mais plus réalistes.\n",
    "\n",
    "Effectuer ces calculs et afficher le taux de bonne classification et la matrice de confusion.\n",
    "\n",
    "**Attention:** il faut donc utiliser les paramètres appris sur de nouvelles données sans réapprendre des paramètres spécifiques sinon ça ne marche pas\n",
    "\n",
    "Afin de mieux comprendre les erreurs (et de vérifier vos connaissances sur numpy): afficher une image de chiffre mal classée, son étiquette prédite et son étiquette réelle. \n",
    "Normalement, vous devez retrouver automatiquement que le premier chiffre mal classé est l'image 10:\n",
    "\n",
    "<img src=\"bad_classif.png\" title=\"exemple d'erreur\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonne classification: 0.6907787552948843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffc916c3bb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_hat = classify_all_images(X_test, mu, sig, -1)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "m = matrice_confusion(Y_test[:50], Y_test_hat[:50])\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres modélisations possibles pour les images\n",
    "\n",
    "## B. Modélisation par une loi de Bernoulli\n",
    "\n",
    "Soit les indices $i$ donnant les images et les indices $j$ référant aux pixels dans l'image, nous cherchons à déterminer la probabilité d'illumination d'un pixel $j$ pour une collection d'image (d'une seule classe, par exemple les $0$).\n",
    "\n",
    "Collection de $0$:\n",
    "$$ X = \\{\\mathbf{x_i}\\}_{i = 1,\\ldots, N}, \\qquad \\mathbf{x_i} \\in \\{0,1\\}^{256}$$\n",
    "\n",
    "Modélisation de la variable de Bernoulli $X_j$, valeur du pixel $j$ en écriture factorisée:\n",
    "$$ p(X_j = x_{ij}) = p_j^{x_{ij}} (1-p_j)^{(1-x_{ij})} = \\left\\{\n",
    "\\begin{array}{ccc}\n",
    "p_j & \\mbox{ si } x_{ij} = 1 \\\\\n",
    "1-p_j & \\mbox{ si } x_{ij} = 0 \\\\\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "Expression de la vraisemblance\n",
    "\n",
    "Maximisation de la vraisemblance $\\Rightarrow$ $\\nabla_{\\theta} \\mathcal L(X, \\theta) = 0$:\n",
    "\n",
    "$$p_j^\\star = \\frac{\\sum_i x_{ij}}{N} $$\n",
    "\n",
    "Intuitif: nombre de $1$ pour le pixel $j$ divisé par le nombre d'image = pourcentage d'illumination du pixel $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffc91eeadf0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# binarisation des images pour coller avec l'hypothèse de Bernoulli:\n",
    "\n",
    "Xb_train = np.where(X_train>0, 1, 0)\n",
    "Xb_test  = np.where(X_test>0, 1, 0)\n",
    "\n",
    "# affichage d'une image binaire:\n",
    "plt.figure()\n",
    "plt.imshow(Xb_train[0].reshape(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-1: Ecrire la fonction d'apprentissage des paramètres qui retourne la matrice theta suivante:\n",
    "\n",
    "$$ \\theta^\\star = \n",
    " \\left[\n",
    " \\begin{array}{ccc}\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Paramètres optimaux de la classe 0 au sens du max de vraisembalnce} \\\\\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Paramètres optimaux de la classe 1 au sens du max de vraisembalnce} \\\\\n",
    "\\vdots & \\\\\n",
    "     [p_0^\\star, \\ldots, p_{255}^\\star] & \\mbox{Paramètres optimaux de la classe 9 au sens du max de vraisembalnce} \\\\\n",
    "\\end{array}\n",
    " \\right]\n",
    " $$\n",
    " \n",
    " Il faut ensuite calculer les :\n",
    " $$ \\log p (\\mathbf{x_i} | \\theta^{(c)}) = \\sum_j \\log p(X_j = x_{ij})  = \\sum_j {x_{ij}} \\log p_j + {(1-x_{ij})}\\log(1-p_j)$$\n",
    " \n",
    " Faire passer les $N$ images dans les $C$ modèles donne un tableau de la forme :\n",
    " $$ \\log p (X | \\theta) =  \\left[\n",
    " \\begin{array}{cccc}\n",
    " \\log p (\\mathbf{x_0} | \\theta^{(0)}) &  \\log p (\\mathbf{x_0} | \\theta^{(1)}) & \\ldots &  \\log p (\\mathbf{x_0} | \\theta^{(9)}) \\\\\n",
    " & \\vdots & \\\\\n",
    " \\log p (\\mathbf{x_N} | \\theta^{(0)}) &  \\log p (\\mathbf{x_N} | \\theta^{(1)}) & \\ldots &  \\log p (\\mathbf{x_N} | \\theta^{(9)}) \\\\\n",
    "  \\end{array}\n",
    " \\right]\n",
    " $$\n",
    " \n",
    " Chaque ligne donne pour une image sa probabilité d'appartenance à chaque classe $c$.\n",
    " Un argmax par ligne donne une estimation de la classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBernoulli ( X,Y ):\n",
    "    res = np.zeros((len(np.unique(Y)),X.shape[1]))\n",
    "    res_final = np.zeros((X.shape[0],len(np.unique(Y))))\n",
    "    for c in np.unique(Y):\n",
    "        \n",
    "        values_class_c = X[np.where(Y == c)]\n",
    "        res[c] = np.mean(values_class_c, axis=0)\n",
    "       \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256)\n",
      "[[0.00093897 0.00657277 0.03192488 ... 0.02347418 0.00375587 0.        ]\n",
      " [0.         0.         0.         ... 0.00233372 0.         0.        ]\n",
      " [0.01941748 0.05987055 0.13430421 ... 0.27993528 0.20711974 0.11326861]\n",
      " ...\n",
      " [0.06666667 0.16078431 0.2745098  ... 0.         0.         0.        ]\n",
      " [0.01033058 0.05371901 0.1322314  ... 0.01446281 0.00206612 0.        ]\n",
      " [0.0037037  0.0037037  0.01111111 ... 0.00555556 0.00185185 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "theta = learnBernoulli ( Xb_train,Y_train )\n",
    "print(theta.shape)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check du résultat précédent:\n",
    "```\n",
    "(10, 256)\n",
    "[[0.00093897 0.00657277 0.03192488 ... 0.02347418 0.00375587 0.        ]\n",
    " [0.         0.         0.         ... 0.00233372 0.         0.        ]\n",
    " [0.01941748 0.05987055 0.13430421 ... 0.27993528 0.20711974 0.11326861]\n",
    " ...\n",
    " [0.06666667 0.16078431 0.2745098  ... 0.         0.         0.        ]\n",
    " [0.01033058 0.05371901 0.1322314  ... 0.01446281 0.00206612 0.        ]\n",
    " [0.0037037  0.0037037  0.01111111 ... 0.00555556 0.00185185 0.        ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-2: Ecrire ensuite une fonction de calcul de la vraisemblance d'une image par rapport à ces paramètres\n",
    "\n",
    "**Attention** $log(0)$ n'est pas défini et $log(1-x)$ avec $x=1$ non plus ! \n",
    "La solution à ce problème est assez simple, il suffit de seuiller les probabilités d'illumination entre $\\epsilon $ et $1-\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpobsBernoulli(X, theta):\n",
    "    eps = 1e-4\n",
    "    theta = np.where(theta == 0, eps, theta)\n",
    "    theta = np.where(theta == 1, 1-eps, theta)\n",
    "    \n",
    "    return np.sum(X * np.log(theta) + (1-X)*np.log(1-theta),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  95.28940214, -913.86894309, -131.15364866, -104.77977757,\n",
       "       -209.07303017,  -85.14159392, -122.04368898, -384.11935833,\n",
       "        -71.06243118, -252.53913188])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpobsBernoulli(X_train[0], theta)\n",
    "# check avec un epsilon = 1e-4 : \n",
    "# array([  95.28940214, -913.86894309, -131.15364866, -104.77977757,\n",
    "#       -209.07303017,  -85.14159392, -122.04368898, -384.11935833,\n",
    "#        -71.06243118, -252.53913188])\n",
    "\n",
    "# ce résultat vous parait-il normal? Qu'est ce qui peut expliquer cette valeur étonnante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-3: Evaluer ensuite vos performances avec les mêmes méthodes que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de bonne classification: 0.8527207559465624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd96a7150a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test_hat = [np.argmax(logpobsBernoulli(Xb_test[i], theta)) for i in range (len(Xb_test))]\n",
    "\n",
    "m = matrice_confusion(Y_test, Y_test_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Modélisation des profils de chiffre\n",
    "\n",
    "Comme expliquer dans le TD 2, il est possible de jouer avec les profils des images: chaque image est alors séparée en 16 lignes et pour chaque ligne, nous modélisons l'apparition du premier pixel allumé avec une loi géométrique.\n",
    "Pour plus de simplicité, nous vous donnons ci-dessous la fonction de transformation de la base d'image et son application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# modelisation geometrique\n",
    "def transfoProfil(X):\n",
    "    x2 = []\n",
    "    for x in X:\n",
    "        ind = np.where(np.hstack((x.reshape(16, 16), np.ones((16,1))))>0.3)\n",
    "        x2.append( [ind[1][np.where(ind[0] == i)][0] for i in range(16)])\n",
    "    return np.array(x2)\n",
    "\n",
    "Xg_train = transfoProfil(Xb_train)\n",
    "Xg_test  = transfoProfil(Xb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 2 2 2 2 1 1 1 2 1 2 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(Xg_train[0]) # [3 2 2 2 2 2 2 1 1 1 2 1 2 2 3 4]\n",
    "# une image est maintenant représentée par 16 entiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-123: Ecrire les fonctions d'apprentissage des paramètres et de calcul de la vraisemblance avec cette modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnGeom ( X,Y):\n",
    "    # votre code ici\n",
    "    pass\n",
    "    \n",
    "def logpobsGeom(X, theta):\n",
    "    # votre code ici\n",
    "    pass\n",
    "    \n",
    "theta = learnGeom(Xg_train, Y_train)\n",
    "\n",
    "print(logpobsGeom(Xg_test[1], theta))\n",
    "\n",
    "Y_train_hat = [np.argmax(logpobsGeom(Xg_train[i], theta)) for i in range (len(Xg_train))]\n",
    "Y_test_hat  = [np.argmax(logpobsGeom(Xg_test[i], theta)) for i in range (len(Xg_test))]\n",
    "\n",
    "ma = matrice_confusion(Y_train, Y_train_hat)\n",
    "mt = matrice_confusion(Y_test, Y_test_hat)\n",
    "\n",
    "print(\"Taux de bonne classification: {}\".format(np.where(Y_test == Y_test_hat, 1, 0).mean()))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ma)\n",
    "plt.figure()\n",
    "plt.imshow(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Maximum a posteriori\n",
    "\n",
    "Etant donné les distributions non uniformes de classes observées sur le jeu de donnée:\n",
    "\n",
    "<img src=\"distr_classes.png\" title=\"Distribution des classes\">\n",
    "\n",
    "Calculer les maxima a posteriori avec les différentes modélisations et vérifier s'il y a un gain en performance avec cette modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des probabilités a priori sur les données d'apprentissage:\n",
    "p= np.histogram(Y_train, np.linspace(-0.5,9.5,11))\n",
    "p = p[0] / p[0].sum()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Fusion de modèle\n",
    "\n",
    "Réussirez-vous à fusionner les sorties des modèles précédents pour améliorer la performance globale en test?\n",
    "* En faisant voter les classifieurs\n",
    "* En pondérant ces votes par leurs performances en apprentissage\n",
    "* En fusionnant les vraisemblances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Proposer une modélisation en 16 niveaux de gris basées sur une loi multinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
